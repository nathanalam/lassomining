{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genome Mining Script\n",
    "##### Original Author: Chun Yin Larry So | Python Interpretation: Nathan Alam\n",
    "[Github repository](https://github.com/nathanalam/genomemining)\n",
    "\n",
    "The purpose of this notebook is to provide scripts for reading bacterial genomes in search of regular expressions which seem to match a String corresponding to a candidate coding for a Lasso peptide.\n",
    "\n",
    "## Links to relevant publications:\n",
    "- [Genome mining for lasso peptides: past, present, and future](https://link.springer.com/article/10.1007/s10295-019-02197-z)\n",
    "- [Prospecting Genomes for Lasso Peptides](https://www.ncbi.nlm.nih.gov/pubmed/24142336)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments from Perl Script\n",
    "- In this version each time MAST needs to be run on a putative maturation enzyme in a particular genome, a lookup in the database is performed to check if this protein has been analyzed by MAST before and if it has then use the values from before\n",
    "- In this version traseq will be used instead of getorf for finding precursors\n",
    "- getorf is still used for finding neighbors\n",
    "- Like v4 except that multiple proteins of the same sequence don't cause wrong locations of maturation enzymes to be reported\n",
    "- Another change is that the pattern needs to be adjusted to [MVL] instead of ^ in the beginning\n",
    "- This version fixes the problem of having a useless %AME hash and also of erasing sequences from %AME_scores\n",
    "- Precursor pattern is output into the log file\n",
    "- ORF searching behavior is changed from stop-to-stop to [MVL]-to-stop\n",
    "- Clusters of precursors are saved in clusters.txt\n",
    "- **Warning**: transeq doesn't label the -1, -2, -3 frames sequentially. Sometimes it is -1, -3, -2, sometimes some other combination. This means the precursor locations on the reverse strand are off by one sometimes\n",
    "- Take note that rank_hits expects 4 motifs for the B enzyme and 3 motifs for the C enzyme. Adjust accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE Pattern\n",
    "\n",
    "This is the pattern that we're using to identify lasso proteins. TODO - Use Machine Learning to adjust the pattern to maximize the number of valid lasso proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN = '^M.{15,45}T..{6,8}[DE].{5,30}$'\n",
    "# PATTERN = 'CC.CGCCC...TGGC.'\n",
    "# PATTERN = '.*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASTA Function\n",
    "\n",
    "Define a function that takes as input the relative path of a FASTA formatted text file, return an object that contains a list of sequence objects. Each sequence object has a description field [\"description\"] and a sequence field [\"sequence\"].\n",
    "\n",
    "From http://www.csbio.sjtu.edu.cn/bioinf/virus-multi/example.htm, specification of a FASTA formatted file:\n",
    "- The first line of each query protein input format must begin with a greater-than (\">\") symbol in the first column. The word following the \">\" symbol is the identifier and description of the sequence, but both are optional.\n",
    "- The sequence (in single-character code) begins in a different line and ends if another line starting with a \">\" appears, which indicates the start of another query protein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFASTA(name, cleanspace = 0):\n",
    "    descriptions = []\n",
    "    sequences = []\n",
    "    sequenceList = []\n",
    "    tempSequences = []     \n",
    "        \n",
    "    with open(name) as file:\n",
    "        count = -1\n",
    "        for line in file:\n",
    "            \n",
    "            if(line[0] == '>'):\n",
    "                # if begins with a >, then a description\n",
    "                descriptions.append(line[1:].replace('\\n', ''))\n",
    "                count += 1\n",
    "                # skip the first time\n",
    "                if count > 0 :\n",
    "                    # combine the tempSequences into a single string and\n",
    "                    # add it to sequences\n",
    "                    newSequence = ' '.join(tempSequences)\n",
    "                    # now remove all of the whitespaces\n",
    "                    newSequence = newSequence.replace(' ', '')\n",
    "                    newSequence = newSequence.replace('\\n', '')\n",
    "                    \n",
    "                    sequences.append(newSequence)\n",
    "                    # refresh the tempSequence list\n",
    "                    tempSequences = []\n",
    "                    \n",
    "                    sequenceList.append({\n",
    "                        \"description\": descriptions[count - 1],\n",
    "                        \"sequence\": sequences[count - 1]\n",
    "                    })\n",
    "            else:\n",
    "                tempSequences.append(line)\n",
    "                \n",
    "        # combine the tempSequences into a single string and\n",
    "        # add it to sequences\n",
    "        newSequence = ' '.join(tempSequences)\n",
    "        # now remove all of the whitespaces\n",
    "        newSequence = newSequence.replace(' ', '')\n",
    "        newSequence = newSequence.replace('\\n', '')\n",
    "\n",
    "        sequences.append(newSequence)\n",
    "        # refresh the tempSequence list\n",
    "        tempSequences = []\n",
    "        \n",
    "        sequenceList.append({\n",
    "            \"description\": descriptions[count],\n",
    "            \"sequence\": sequences[count]\n",
    "        })\n",
    "                \n",
    "                \n",
    "    if len(descriptions) != len(sequences):\n",
    "        print(\"ERROR: Number of descriptions does not match number of sequences\")\n",
    "        print(\"Number of descriptions: \" + str(len(descriptions)))\n",
    "        print(\"Number of sequences: \" + str(len(sequences)))\n",
    "        sys.exit(1);\n",
    "        \n",
    "    print(\"Read \" + str(count + 1) + \" objects from FASTA file \" + name)\n",
    "        \n",
    "    return sequenceList\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Amino acid sequence directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by getting a list of all of the genomes available in the genomes folder alongside this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLDIRNAMES = []\n",
    "for dirname in os.listdir(\"genomes\"):\n",
    "    ALLDIRNAMES.append(\"genomes/\" + dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the fna files, we need to convert them to amino acid sequences (or faa files). We do this using [Emboss Transeq](https://www.ebi.ac.uk/seqdb/confluence/display/JDSAT/EMBOSS+transeq+Help+and+Documentation#EMBOSStranseqHelpandDocumentation-Reference), and save the output amino acid sequences into this genome file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "url = \"https://www.ebi.ac.uk/Tools/services/rest/emboss_transeq\"\n",
    "\n",
    "## An adapter function for the Emboss transeq, takes in a DNA sequence and returns a list of protein sequences\n",
    "def emboss_transeq(DNAseq):\n",
    "    payload = \"email=nalam@princeton.edu&sequence=\" + DNAseq + \"&codontable=11&frame=6\"\n",
    "    headers = {\n",
    "        'Content-Type': \"application/x-www-form-urlencoded\",\n",
    "        'Accept': \"text/plain\",\n",
    "        'User-Agent': \"PostmanRuntime/7.13.0\",\n",
    "        'Cache-Control': \"no-cache\",\n",
    "        'Postman-Token': \"e19f3174-9eb3-43e2-ade4-c73702e88fa0,43c05bc6-a184-4288-8e52-bef78f1f9a9b\",\n",
    "        'Host': \"www.ebi.ac.uk\",\n",
    "        'accept-encoding': \"gzip, deflate\",\n",
    "        'content-length': \"282\",\n",
    "        'Connection': \"keep-alive\",\n",
    "        'cache-control': \"no-cache\"\n",
    "        }\n",
    "    abbrevlen = 25 \n",
    "    if (25 > len(DNAseq)):\n",
    "        abbrevlen = len(DNAseq) \n",
    "    print(\"Beginning training job for \" + DNAseq[:abbrevlen] + \"...\")\n",
    "    \n",
    "    response = requests.request(\"POST\", url + \"/run\", data=payload, headers=headers)\n",
    "    jobID = response.text\n",
    "    print(\"Job begun with jobID \" + jobID)\n",
    "    \n",
    "    stat = \"RUNNING\"\n",
    "    \n",
    "    while(stat != \"FINISHED\"):\n",
    "        response = requests.request(\"GET\", url + \"/status/\" + jobID, headers=headers)\n",
    "        print(response.text)\n",
    "        stat = response.text\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    if stat == \"FINISHED\":\n",
    "        print(\"Requesting results for \" + jobID)\n",
    "        response = requests.request(\"GET\", url + \"/result/\" + jobID + \"/out\", headers=headers)\n",
    "        print(\"Writing results to temp.faa\")\n",
    "        with open('temp.faa', 'w') as outfile:\n",
    "            outfile.write(response.text)\n",
    "        print(\"Reading results with FASTA reader from temp.faa\")\n",
    "        seqList = readFASTA(\"temp.faa\")\n",
    "        \n",
    "        print(\"Finished reading, now removing temp.faa\")\n",
    "        os.remove(\"temp.faa\")\n",
    "        \n",
    "        returnList = []\n",
    "        for obj in seqList:\n",
    "            returnList.append(obj[\"sequence\"])\n",
    "        return returnList\n",
    "\n",
    "    else:\n",
    "        print(\"Something went horribly wrong...\")\n",
    "        return []\n",
    "    \n",
    "#     AAList = [\"\", \"\", \"\", \"\", \"\", \"\"]\n",
    "#     codon = \"\"\n",
    "#     for e in range(0, 6):\n",
    "#         AAList[e] = 'A' * int(len(DNAseq) / 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training job for AUG...\n",
      "Job begun with jobID emboss_transeq-R20190930-182012-0830-7651441-p2m\n",
      "RUNNING\n",
      "FINISHED\n",
      "Requesting results for emboss_transeq-R20190930-182012-0830-7651441-p2m\n",
      "Writing results to temp.faa\n",
      "Reading results with FASTA reader from temp.faa\n",
      "Read 6 objects from FASTA file temp.faa\n",
      "Finished reading, now removing temp.faa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['M', 'X', 'X', 'H', 'X', 'X']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emboss_transeq(\"AUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening up genomes/btha.fna and converting into peptide sequences...\n",
      "Read 1 objects from FASTA file genomes/btha.fna\n",
      "converting 37774 base pairs from gi|83716035|ref|NC_007650|pseudocap|177 [Burkholderia thailandensis E264 chromosome II, complete sequence.]\n",
      "Beginning training job for ATGACTCTCGACGAGATCCGGCAAT...\n",
      "Job begun with jobID emboss_transeq-R20190930-182130-0850-95857415-p2m\n",
      "FINISHED\n",
      "Requesting results for emboss_transeq-R20190930-182130-0850-95857415-p2m\n",
      "Writing results to temp.faa\n",
      "Reading results with FASTA reader from temp.faa\n",
      "Read 6 objects from FASTA file temp.faa\n",
      "Finished reading, now removing temp.faa\n",
      "created 6 peptide sequences from gi|83716035|ref|NC_007650|pseudocap|177 [Burkholderia thailandensis E264 chromosome II, complete sequence.]\n",
      "writing read peptides into 'btha.faa'\n"
     ]
    }
   ],
   "source": [
    "for dirname in ALLDIRNAMES:\n",
    "    if((dirname[len(dirname) - 3:] == \"fna\") and not (dirname[:len(dirname) - 3] + \"faa\") in ALLDIRNAMES):\n",
    "        print(\"Opening up \" + dirname + \" and converting into peptide sequences...\")\n",
    "        DNAseqs = []\n",
    "        seqDescriptions = []\n",
    "        for fastaobj in readFASTA(dirname):\n",
    "            DNAseqs.append(fastaobj[\"sequence\"])\n",
    "            seqDescriptions.append(fastaobj[\"description\"])\n",
    "            \n",
    "        entries = []\n",
    "        for i in range(0, len(DNAseqs)):\n",
    "            print(\"converting \" + str(len(DNAseqs[i])) + \" base pairs from \" + seqDescriptions[i])\n",
    "            aalist = emboss_transeq(DNAseqs[i])\n",
    "            print(\"created \" + str(len(aalist)) + \" peptide sequences from \" + seqDescriptions[i])\n",
    "            for e in range(0, len(aalist)):\n",
    "                entries.append({\n",
    "                    \"sequence\": aalist[e],\n",
    "                    \"description\": str(seqDescriptions[i] + \" - peptide \" + str(e)) \n",
    "                })\n",
    "        \n",
    "        print(\"writing read peptides into '\" + dirname[len('genomes/'):len(dirname) - 3] + \"faa'\")\n",
    "        with open(dirname[:len(dirname) - 3] + \"faa\", 'w') as outfile:\n",
    "            for ent in entries:\n",
    "                outfile.write(\"> \" + ent[\"description\"] + \"\\n\")\n",
    "                outfile.write(ent[\"sequence\"] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we append all of the files ending in a \".faa\" translation to an array of files called DIRNAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['genomes/btha.faa']\n"
     ]
    }
   ],
   "source": [
    "DIRNAMES = []\n",
    "for dirname in os.listdir(\"genomes\"):\n",
    "    if(dirname[len(dirname) - 3:] == \"faa\"):\n",
    "        DIRNAMES.append(\"genomes/\" + dirname)\n",
    "        \n",
    "print(DIRNAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Matching\n",
    "Uses the python regular expression library to determine whether proteins match the pattern sequence. This function takes in an overall sequence of amino acids and determines whether the sequence passes the pattern regular expression. The function returns a list of matched proteins, which have a specific sequence, and stores the overall sequence and the associated description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patternMatch(overallSequence, pattern, description):\n",
    "    matchedProteinList = []\n",
    "    \n",
    "    # find all matches in protein that match\n",
    "    matchIter = re.finditer(pattern, overallSequence)\n",
    "    done_looping = False\n",
    "    while not done_looping:\n",
    "        try:\n",
    "            match = next(matchIter)\n",
    "        except StopIteration:\n",
    "            done_looping = True\n",
    "        else:\n",
    "            matchedProteinList.append({\n",
    "                \"description\": description,\n",
    "                \"sequence\": match.group(0),\n",
    "                \"searchPattern\": match.re.pattern,\n",
    "                \"searchRange\": match.span(),\n",
    "                \"overallString\": match.string\n",
    "            })\n",
    "    return matchedProteinList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 6 objects from FASTA file genomes/btha.faa\n",
      "Found 0 that satisfy the pattern: ^M.{15,45}T..{6,8}[DE].{5,30}$\n"
     ]
    }
   ],
   "source": [
    "matchedProteins = []\n",
    "for filename in DIRNAMES:\n",
    "    readSequences = readFASTA(filename)\n",
    "    for seq in readSequences:\n",
    "        matchedProteins.extend(patternMatch(seq[\"sequence\"], PATTERN, filename + \" - \" + seq[\"description\"]))\n",
    "    \n",
    "\n",
    "print(\"Found \" + str(len(matchedProteins)) + \" that satisfy the pattern: \" + PATTERN)\n",
    "# for match in matchedProteins:\n",
    "#     print(match[\"sequence\"] + \", found in range \" + str(match[\"searchRange\"]))\n",
    "#     print(\"description: \" + match[\"description\"])\n",
    "\n",
    "for match in matchedProteins:\n",
    "    print(match[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matches.json', 'w') as outfile:\n",
    "    json.dump(matchedProteins, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "lassopeptides = []\n",
    "with open('matches.json', 'r') as storedfile:\n",
    "    lassopeptides = json.loads(storedfile.read())\n",
    "\n",
    "print(lassopeptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
